+++
date = "2016-09-18T10:44:45-07:00"
location = "Boulder"
tags = ["projects", "hardware", "favorites"]
thumbnail = "/img/carputer-innards-thumbnail.png"
title = "AVC 2016"

+++

Me and some friends worked on a car for [Sparkfun's Autonomous Vehicle Competition](http://avc.sparkfun.com),
held each year in Boulder.
The competition has your car make one (just one!) lap around their haybale-bordered track.
There are dirt sections, hoops to go through, barrels to dodge, jumps, zigzags
and the famous "discombobulator" -- a spinning disc that most competitors just try to jump if they approach it at all.

Our entry, "Neural Carputer," used a four layer convolutional neural network
that was trained on a single front-facing camera and the car's odometer.
We took about an hour of training data,
having someone just manually drive around the course the day before the race.
In autonomous mode, Carputer made one perfect run around the course on race day
and had many more less-than-perfect runs too (:

<!--more-->


*the hardware*

![carputer hardware](/img/carputer-hardware.png)

Carputer's raced in three AVCs now and the hardware's evolved over the years..
one arduino takes RC input data, another arduino sends servo commands, and in between..
a Macbook Pro retina with an Nvidia GPU running our control software, haha.
The Macbook is definitely overkill but it lets us take data, train, update and test very quickly.

The chassis is an RC car that we exteneded to accomodate the laptop.
Our camera is mounted into the plastic body of the car.
We use a 3S lipo but stay far away from the car's 60mph+ max speed.
There used to be a lidar in the mix but we couldn't quite get that working the way we wanted.


*the software*

We'll open source it soon --
it uses tensorflow and a bunch of data pre- and post-processing scripts.


*our autonomous runs on the Sparkfun course*

{{% youtube asdf %}}

Our first test run in the early morning light was amazing -- it completed a full lap,
only lightly grazing a barrier on the backstretch.
We had actually trained that particular model during the drive to the track
after applying two new ideas the night before.
We were really pumped about the car's morning performance but,
sadly, this would be our best run of the day..

{{% youtube asdf %}}

We competed in three official heats:
the first heat had our car roll forward with great promise for about 3m and then promptly hit the brakes.
It sat there stubbornly until the judges made us clear the track..quite a letdown, hah.
Our logs showed that the remote override had been activated,
and I had been holding the RC transmitter, but I didn't think I had hit our e-stop button.
We later saw this happen during test runs and attributed it to RC noise --
we just deactivated our remote kill switch so it wouldn't happen again.

{{% youtube asdf %}}

Our second heat was the most exciting run I saw from any car --
Carputer fought through several haybales
and then took an unplanned turn towards the discombobulator

{{% youtube asdf %}}

Our final official race was quite anticlimatic --
we had added a throttle hack to try and slow down just for the first turn..
that, a new untested model, and some camera white balance issues
left us driving uncertainly towards an SFE videographer and then into a haybale.
(Hm, it also looks like our steering trim is way off after crashing so much during the day --
we're sending "89" to the steering servo but drifting way left.
Compare that to the 89s we send in the first video..)

{{% youtube asdf %}}

We also had the car go into the rumble --
it gets a lot of human assistance on those laps (:


*various tricks that helped us this year*

* we "class balanced" our network by randomly tossing 70% of training data
that just had the car going straight-ish -- this allowed the network to learn more from turns.
It helped make up for the fact that most of the driving is on straightaways
* our odometer wasn't the fanciest and so we were worried about drift --
to counteract this we binned our odo data to effectively divide the track into segments.
Our hope was that the car would learn to handle certain images based on its rough position on the track
* we also had a mechanism to reset the car's odometer during training


*next year*

* learn about how to avoid RC interference
* figure out white balancing issues
* trim the steering more often
* reattach the lidar and get that working (:
